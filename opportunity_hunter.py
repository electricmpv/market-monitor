#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ” æœºä¼šçŒæ‰‹ v2.0 - èèµ„ã€åˆ›ä¸šã€æŠ€æœ¯çªç ´ç›‘æ§
Author: ç”µåŠ¨é¢åŒ…
Purpose: å‘ç°èèµ„é¡¹ç›®ã€åˆ›ä¸šå›¢é˜Ÿã€æŠ€æœ¯çªç ´
"""

import os
import datetime
import time
import hashlib
import json
import sys
from pathlib import Path

try:
    from google import genai
    import requests
    import chromadb
    from docx import Document
    from docx.shared import Pt, RGBColor
except ImportError as e:
    print(f"âŒ ä¾èµ–åº“ç¼ºå¤±: {e}")
    sys.exit(1)

# ==================== ğŸ› ï¸ ç”¨æˆ·é…ç½®åŒº ====================

GEMINI_KEY = os.getenv('GEMINI_API_KEY', 'å¡«å…¥è‡ªå·±çš„API-key')
PUSHPLUS_TOKEN = os.getenv('PUSHPLUS_TOKEN', 'å¡«å…¥è‡ªå·±çš„TOKEN')
GITHUB_TOKEN = os.getenv('GITHUB_TOKEN', '')

YOUR_PORT = int(os.getenv('PROXY_PORT', 19828))
USE_PROXY = YOUR_PORT > 0

# GitHubæœç´¢å…³é”®è¯ - ç²¾ç¡®ç‰ˆ
GITHUB_KEYWORDS = [
    # AI Agentæ¡†æ¶
    'AI agent framework', 'LLM agent', 'autonomous agent',
    'agent orchestration', 'multi-agent',
    
    # RAGç³»ç»Ÿ
    'RAG pipeline', 'retrieval augmented', 'vector database',
    'semantic search', 'knowledge graph',
    
    # æç¤ºå·¥ç¨‹
    'prompt engineering', 'prompt optimization',
    'prompt template', 'few-shot learning',
    
    # è‡ªåŠ¨åŒ–
    'workflow automation', 'task automation',
    'browser automation', 'API automation',
    
    # æ–°å·¥å…·
    'LLM framework', 'AI framework', 'generative AI',
    'DeepSeek', 'Claude integration', 'GPT wrapper'
]

# GitHubè¿‡æ»¤
MIN_STARS = 300
DAYS_SINCE_UPDATE = 90

# Hacker Newså…³é”®è¯
HN_KEYWORDS = [
    'AI', 'machine learning', 'LLM', 'GPT', 'Claude',
    'startup', 'funding', 'Series A', 'Series B',
    'open source', 'breakthrough', 'SOTA'
]

# =======================================================================

if USE_PROXY:
    PROXY_URL = f'http://127.0.0.1:{YOUR_PORT}'
    os.environ['http_proxy'] = PROXY_URL
    os.environ['https_proxy'] = PROXY_URL
    print(f"ğŸ“¡ ä»£ç†å·²å¯ç”¨: {PROXY_URL}")

DATA_DIR = Path('./my_market_brain')
DATA_DIR.mkdir(exist_ok=True)

print(f"ğŸ” æœºä¼šçŒæ‰‹ v2.0 å¯åŠ¨... [æ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}]")

try:
    gemini_client = genai.Client(api_key=GEMINI_KEY)
    chroma_client = chromadb.PersistentClient(path=str(DATA_DIR))
    opportunity_collection = chroma_client.get_or_create_collection(name="opportunities_v2")
    print("âœ… æ‰€æœ‰ç»„ä»¶åŠ è½½å®Œæ¯•")
except Exception as e:
    print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
    sys.exit(1)

current_session_opportunities = []

# ==================== å·¥å…·å‡½æ•° ====================

def create_robust_session():
    """åˆ›å»ºæŠ—ç½‘ç»œæ³¢åŠ¨çš„ä¼šè¯"""
    session = requests.Session()
    if USE_PROXY:
        session.proxies = {"http": PROXY_URL, "https": PROXY_URL}
    return session

http = create_robust_session()

def save_opportunity(source, title, description, link, metadata):
    """ä¿å­˜æœºä¼š"""
    try:
        content = f"{source}: {title} | {description}"
        content_fingerprint = hashlib.md5(content.encode('utf-8')).hexdigest()
        doc_id = f"OPP_{source}_{content_fingerprint}"
        
        # æ£€æŸ¥é‡å¤
        existing = opportunity_collection.get(ids=[doc_id])
        if existing and existing['ids']:
            return False
        
        current_time = datetime.datetime.now().isoformat()
        opportunity_collection.upsert(
            documents=[content],
            metadatas=[{
                "source": source,
                "title": title,
                "type": metadata.get('type', 'unknown'),
                "time": current_time,
                "link": link
            }],
            ids=[doc_id]
        )
        
        current_session_opportunities.append({
            'source': source,
            'title': title,
            'description': description,
            'link': link,
            'metadata': metadata,
            'time': current_time
        })
        
        print(f"  ğŸ’¡ [{source}] {title[:50]}...")
        return True
    except Exception as e:
        print(f"  âš ï¸ ä¿å­˜å¤±è´¥: {e}")
        return False

def hunt_github():
    """GitHubé¡¹ç›®çŒæ‰‹"""
    print("\nğŸ™ [1/2] æ­£åœ¨æ‰«æ GitHub...")
    count = 0
    
    headers = {
        'Accept': 'application/vnd.github.v3+json',
        'User-Agent': 'MarketHunter/v2'
    }
    if GITHUB_TOKEN:
        headers['Authorization'] = f'token {GITHUB_TOKEN}'
    
    try:
        for keyword in GITHUB_KEYWORDS[:5]:  # æ¯æ¬¡é€‰5ä¸ªå…³é”®è¯
            print(f"  ğŸ” æœç´¢: {keyword}")
            
            api_url = f"https://api.github.com/search/repositories?q={keyword}+stars:>{MIN_STARS}&sort=updated&order=desc&per_page=3"
            
            try:
                resp = http.get(api_url, headers=headers, timeout=15)
                
                if resp.status_code == 200:
                    items = resp.json().get('items', [])
                    
                    for item in items:
                        updated_at = item['updated_at'][:10]
                        last_update = datetime.datetime.strptime(updated_at, "%Y-%m-%d")
                        days_diff = (datetime.datetime.now() - last_update).days
                        
                        if days_diff > DAYS_SINCE_UPDATE:
                            continue
                        
                        if save_opportunity(
                            source="GitHub",
                            title=item['full_name'],
                            description=item['description'] or "No description",
                            link=item['html_url'],
                            metadata={
                                'type': 'OpenSource',
                                'stars': item['stargazers_count'],
                                'language': item['language'],
                                'updated': updated_at
                            }
                        ):
                            count += 1
                
                elif resp.status_code == 403:
                    print("â›” GitHub API é¢‘ç‡è¶…é™")
                    break
                
                time.sleep(1)
                
            except Exception as e:
                print(f"     âš ï¸ æœç´¢å‡ºé”™: {e}")
                continue
    
    except Exception as e:
        print(f"âŒ GitHub æ‰«æå¤±è´¥: {e}")
    
    return count

def hunt_hacker_news():
    """Hacker Newsæœºä¼šçŒæ‰‹"""
    print("\nğŸ“° [2/2] æ­£åœ¨æ‰«æ Hacker News...")
    count = 0
    
    try:
        resp = requests.get(
            'https://hacker-news.firebaseio.com/v0/topstories.json',
            timeout=10
        )
        top_ids = resp.json()[:15]
        
        for item_id in top_ids:
            try:
                item = requests.get(
                    f'https://hacker-news.firebaseio.com/v0/item/{item_id}.json',
                    timeout=10
                ).json()
                
                if item and item.get('score', 0) >= 150:
                    title = item.get('title', '')
                    text = item.get('text', '')
                    url = item.get('url', '')
                    
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«æœºä¼šå…³é”®è¯
                    content_lower = (title + text).lower()
                    is_opportunity = False
                    opp_type = 'News'
                    
                    if any(kw in content_lower for kw in ['funding', 'series', 'raised', 'investment']):
                        is_opportunity = True
                        opp_type = 'Funding'
                    elif any(kw in content_lower for kw in ['startup', 'founded', 'launch']):
                        is_opportunity = True
                        opp_type = 'Startup'
                    elif any(kw in content_lower for kw in ['breakthrough', 'SOTA', 'new', 'release']):
                        is_opportunity = True
                        opp_type = 'Technology'
                    
                    if is_opportunity:
                        if save_opportunity(
                            source="HackerNews",
                            title=title,
                            description=text[:200],
                            link=url,
                            metadata={
                                'type': opp_type,
                                'score': item.get('score', 0)
                            }
                        ):
                            count += 1
                
                time.sleep(0.5)
            except:
                pass
    
    except Exception as e:
        print(f"âŒ HN æ‰«æå¤±è´¥: {e}")
    
    return count

def analyze_opportunities_ai(raw_data):
    """AIåˆ†ææœºä¼š"""
    print("\nğŸ§  æ­£åœ¨ç”¨AIåˆ†ææœºä¼š...")
    
    prompt = f"""
# Role: Investment & Startup Analyst
# Task: ä»æŠ€æœ¯æ–°é—»å’Œå¼€æºé¡¹ç›®ä¸­è¯†åˆ«å•†ä¸šæœºä¼š

## åˆ†æç»´åº¦
1. **èèµ„ä¿¡å·** - å“ªäº›åˆ›ä¸šå…¬å¸è·å¾—èèµ„ï¼Ÿä¸ºä»€ä¹ˆï¼Ÿ
2. **æŠ€æœ¯è¶‹åŠ¿** - å“ªäº›æŠ€æœ¯æ–¹å‘åœ¨å‡æ¸©ï¼Ÿ
3. **å·¥å…·æœºä¼š** - å“ªäº›å¼€æºé¡¹ç›®å¯èƒ½å•†ä¸šåŒ–ï¼Ÿ
4. **å¸‚åœºç¼ºå£** - è¿˜æœ‰å“ªäº›æœªè¢«æ»¡è¶³çš„éœ€æ±‚ï¼Ÿ

## æ•°æ®
{raw_data}

## è¾“å‡ºæ ¼å¼
### ğŸ¯ Top 5 æœºä¼š

1. [æœºä¼šåç§°]
   - ç±»å‹: [èèµ„/æŠ€æœ¯/å·¥å…·/å¸‚åœº]
   - æ ¸å¿ƒä»·å€¼: ...
   - ä¸ºä»€ä¹ˆé‡è¦: ...
   - ä½ çš„è¡ŒåŠ¨: ...

2. [æœºä¼šåç§°]
   ...

### ğŸ“Š è¶‹åŠ¿æ€»ç»“
- æœ€çƒ­è¯é¢˜: ...
- èèµ„çƒ­åº¦: ...
- æŠ€æœ¯æ–¹å‘: ...
"""
    
    max_retries = 3
    for attempt in range(max_retries):
        try:
            response = gemini_client.models.generate_content(
                model='gemini-2.5-flash',
                contents=prompt
            )
            return response.text
        except Exception as e:
            print(f"âš ï¸ åˆ†æå°è¯• {attempt+1} å¤±è´¥: {e}")
            if attempt < max_retries - 1:
                time.sleep(5)
    
    return "âŒ AIåˆ†æå¤±è´¥"

def deliver_report(content):
    """äº¤ä»˜æŠ¥å‘Š"""
    if content.startswith("âŒ"):
        print(f"\nğŸš« {content}")
        return
    
    today = datetime.date.today().strftime("%Y-%m-%d")
    filename = f"Opportunities_Report_{today}.docx"
    
    # ä¿å­˜Word
    try:
        doc = Document()
        doc.add_heading(f'ğŸ” æœºä¼šå‘ç°æŠ¥å‘Š - {today}', 0)
        doc.add_paragraph(f"ç”Ÿæˆæ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        doc.add_paragraph(f"å‘ç°æœºä¼šæ•°: {len(current_session_opportunities)}")
        doc.add_paragraph("=" * 50)
        
        for line in content.split('\n'):
            line = line.strip()
            if not line:
                continue
            if line.startswith('# '):
                doc.add_heading(line.replace('# ', ''), level=1)
            elif line.startswith('## '):
                doc.add_heading(line.replace('## ', ''), level=2)
            elif line.startswith('### '):
                doc.add_heading(line.replace('### ', ''), level=3)
            else:
                doc.add_paragraph(line)
        
        doc.save(filename)
        print(f"\nğŸ’¾ âœ… æŠ¥å‘Šå·²ç”Ÿæˆ: {filename}")
    except Exception as e:
        print(f"âŒ Wordç”Ÿæˆå¤±è´¥: {e}")
    
    # æ¨é€å¾®ä¿¡
    if PUSHPLUS_TOKEN and PUSHPLUS_TOKEN != 'å¡«å…¥è‡ªå·±çš„TOKEN':
        try:
            print("ğŸ“¨ æ­£åœ¨æ¨é€åˆ°å¾®ä¿¡...")
            wechat_body = f"# ğŸ” æœºä¼šå‘ç°æŠ¥å‘Š ({today})\n\n{content}"
            
            requests.post(
                'http://www.pushplus.plus/send',
                json={
                    "token": PUSHPLUS_TOKEN,
                    "title": f"ã€æœºä¼šã€‘{today}",
                    "content": wechat_body,
                    "template": "markdown"
                },
                timeout=10
            )
            print("ğŸ“¨ âœ… å¾®ä¿¡æ¨é€å®Œæˆ")
        except Exception as e:
            print(f"âš ï¸ æ¨é€å¤±è´¥: {e}")

# ==================== ä¸»ç¨‹åº ====================

def main():
    print("\n" + "="*60)
    print("ğŸš€ å¼€å§‹æœºä¼šçŒæ‰‹å¾ªç¯")
    print("="*60)
    
    c1 = hunt_github()
    c2 = hunt_hacker_news()
    
    total = c1 + c2
    print(f"\nğŸ“Š æœ¬æ¬¡å‘ç°æœºä¼šæ•°: {total}")
    
    if total > 0:
        raw_opps = "\n".join([
            f"ã€{o['source']}ã€‘{o['title']}: {o['description']}"
            for o in current_session_opportunities
        ])
        
        analysis = analyze_opportunities_ai(raw_opps)
        deliver_report(analysis)
    else:
        print("ğŸ¤· æœªå‘ç°æ–°æœºä¼š")
    
    print("\nâœ… æœºä¼šçŒæ‰‹å¾ªç¯å®Œæˆ")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
